services:
  sender:
    build: ./sender
    volumes:
      - ./sender:/app # Mount source code
      - ./runs:/app/runs
      - ./models:/app/models
      - ./sender/utils:/app/utils:ro # Mount utils to ensure it's available and up-to-date
    expose:
      - "65500" # <-- ADD THIS LINE
    environment:
      - DATASET_TYPE=CIFAR10 # Options: CIFAR10, STL10, CUSTOM
      - EXPERIMENT_STEPS=${EXPERIMENT_STEPS:-5000} # Number of steps to run the experiment (default 5000)
      - BASELINE=${BASELINE:-DRL} # Baseline mode: DRL, RAW, HEURISTIC
      - LOAD_MODEL=${LOAD_MODEL} # Optional: Model to load
    depends_on:
      - edge-encoder
      - edge-decoder
    deploy:
      resources:
        limits:
          cpus: "1.5"
    # ... other sender config ...

  receiver:
    build: ./receiver
    volumes:
      - ./runs:/app/runs
      - ./models:/app/models
      - ./sender/utils:/app/utils:ro # Share utils from sender
    ports:
      - "65432:65432" # This is fine if you want to see receiver output
    depends_on:
      - sender
      - channel
    # ... other receiver config ...

  channel:
    build: ./channel
    ports:
      - "65431:65431"
    cap_add:
      - NET_ADMIN
    depends_on:
      - sender
    # ... other channel config ..

  edge-encoder:
    build: ./edge_encoder
    volumes:
      - ./models:/app/models:ro
      - ./sender/utils:/app/utils:ro
    expose:
      - "8000"

  edge-decoder:
    build: ./edge_decoder
    volumes:
      - ./models:/app/models:ro
      - ./sender/utils:/app/utils:ro
    expose:
      - "8000"
